{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dcd30527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dad5c2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_bigquery_query_cost(bq_client, query):\n",
    "    \n",
    "    job_config = bigquery.QueryJobConfig()\n",
    "    job_config.dry_run = True\n",
    "    job_config.use_query_cache = False\n",
    "    query_job = bq_client.query(\n",
    "\n",
    "        (\n",
    "           query\n",
    "        ),\n",
    "        job_config=job_config,\n",
    "    )\n",
    "    \n",
    "    cost_euros = (query_job.total_bytes_processed / 1024 ** 4) * 6\n",
    "\n",
    "    print(f\"{query_job.total_bytes_processed} bytes will be processed , cost ~{cost_euros}$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ebb91b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigquery_client= bigquery.Client(project=\"ingka-energy-analytics-dev\") # ingka-energy-solar-dev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a9b500",
   "metadata": {},
   "source": [
    "## Landings data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8557ebae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35755206733 bytes will be processed , cost ~0.19511502650675538$\n"
     ]
    }
   ],
   "source": [
    "# Visited pages\n",
    "query_string = \"\"\"\n",
    "SELECT \n",
    "    date_hit\n",
    "    , visitor_id\n",
    "    , session_id\n",
    "    , page_urls\n",
    "FROM (\n",
    "    SELECT \n",
    "    date_hit\n",
    "    , visitor_id\n",
    "    , session_id\n",
    "    , page_urls\n",
    "    , EXISTS(SELECT * FROM UNNEST(page_urls) AS x WHERE REGEXP_CONTAINS(x, \".+?clean-energy.+\")) as exist\n",
    "    FROM (\n",
    "        SELECT \n",
    "            date_hit\n",
    "            , visitor_id\n",
    "            , session_id\n",
    "            , ARRAY_AGG(page_url) as page_urls\n",
    "        FROM `ingka-web-analytics-prod.web_data_v2.hits_events_and_pages` \n",
    "        WHERE \n",
    "            date_hit = '2022-07-01' \n",
    "            -- AND website_market_short in ('se')\n",
    "            AND event_category like '%page%'\n",
    "            AND page_url is not NULL\n",
    "        GROUP BY\n",
    "            date_hit\n",
    "            , visitor_id\n",
    "            , session_id\n",
    "        ORDER BY visitor_id\n",
    "    ) pages\n",
    ")\n",
    "WHERE exist is TRUE\n",
    "LIMIT 1000\n",
    "\"\"\"\n",
    "\n",
    "estimate_bigquery_query_cost(bigquery_client, query_string) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b280a3",
   "metadata": {},
   "source": [
    "## Searches data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d6665696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"solar\" in UNNEST(internal_search_terms) OR \"sol\" in UNNEST(internal_search_terms) OR \"sunpower\" in UNNEST(internal_search_terms) OR \"svea\" in UNNEST(internal_search_terms) OR \"solstrale\" in UNNEST(internal_search_terms) OR \"solstråle\" in UNNEST(internal_search_terms) OR \"solpaneler\" in UNNEST(internal_search_terms) \n",
      "\n",
      "294315395349 bytes will be processed , cost ~1.6060697563207214$\n"
     ]
    }
   ],
   "source": [
    "# Get SQL string filter condition\n",
    "product_string_queries = [\n",
    "    'solar', 'sol', 'sunpower', 'svea', 'solstrale', 'SOLSTRÅLE', 'solpaneler',\n",
    "]\n",
    "string_exp = ' OR '.join([f'\"{exp.lower()}\" in UNNEST(internal_search_terms)' for exp in product_string_queries])\n",
    "print(string_exp,'\\n')\n",
    "\n",
    "\n",
    "# Download query results.\n",
    "query_string = \"\"\"\n",
    "SELECT *\n",
    "FROM (\n",
    "    SELECT \n",
    "        date_hit\n",
    "        , visitor_id\n",
    "        , session_id\n",
    "        , website_market_short\n",
    "        , website_language_short\n",
    "        , ARRAY_AGG(DISTINCT LOWER(internal_search_term)) as internal_search_terms\n",
    "    FROM `ingka-web-analytics-prod.web_data_v2.hits_events_and_pages` \n",
    "    WHERE \n",
    "        date_hit >= '2022-07-02' \n",
    "        AND website_market_short in ('us','se')\n",
    "        AND event_category like '%search%'\n",
    "        AND internal_search_type = 'hard_search'\n",
    "        AND internal_search_term is not Null\n",
    "    GROUP BY\n",
    "        date_hit\n",
    "        , visitor_id\n",
    "        , session_id\n",
    "        , website_market_short\n",
    "        , website_language_short\n",
    "    ORDER BY visitor_id\n",
    ") searches\n",
    "WHERE \n",
    "    {exp}\n",
    "\"\"\".format(exp=string_exp)\n",
    "\n",
    "estimate_bigquery_query_cost(bigquery_client, query_string) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d428e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table.RowIterator at 0x17f36b0a0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write to table\n",
    "table_id=\"ingka-energy-analytics-dev.ces_da_playground.searches_temp\"\n",
    "\n",
    "job_config = bigquery.QueryJobConfig(\n",
    "    allow_large_results=True, destination=table_id, use_legacy_sql=False,\n",
    "    write_disposition = \"WRITE_TRUNCATE\"\n",
    ")\n",
    "\n",
    "\n",
    "bigquery_client.query(\n",
    "    query_string, \n",
    "    job_config=job_config\n",
    ").result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2fd770fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequest",
     "evalue": "400 Resources exceeded during query execution: The query could not be executed in the allotted memory. Peak usage: 123% of limit.\nTop memory consumer(s):\n  ORDER BY operations: 99%\n  other/unattributed: 1%\n\n\nLocation: EU\nJob ID: d7a36c40-02a1-441e-a781-e02b192b843a\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequest\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [58]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m job_config \u001b[38;5;241m=\u001b[39m bigquery\u001b[38;5;241m.\u001b[39mQueryJobConfig(\n\u001b[1;32m      2\u001b[0m     use_legacy_sql\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      5\u001b[0m df \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m----> 6\u001b[0m     \u001b[43mbigquery_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;241m.\u001b[39mto_dataframe(\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;66;03m# Optionally, explicitly request to use the BigQuery Storage API. As of\u001b[39;00m\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;66;03m# google-cloud-bigquery version 1.26.0 and above, the BigQuery Storage\u001b[39;00m\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;66;03m# API is used by default.\u001b[39;00m\n\u001b[1;32m     12\u001b[0m         create_bqstorage_client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     13\u001b[0m     )\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     16\u001b[0m df\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/google/cloud/bigquery/job/query.py:1499\u001b[0m, in \u001b[0;36mQueryJob.result\u001b[0;34m(self, page_size, max_results, retry, timeout, start_index, job_retry)\u001b[0m\n\u001b[1;32m   1496\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m retry_do_query \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m job_retry \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1497\u001b[0m         do_get_result \u001b[38;5;241m=\u001b[39m job_retry(do_get_result)\n\u001b[0;32m-> 1499\u001b[0m     \u001b[43mdo_get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mGoogleAPICallError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m   1502\u001b[0m     exc\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m=\u001b[39m _EXCEPTION_FOOTER_TEMPLATE\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1503\u001b[0m         message\u001b[38;5;241m=\u001b[39mexc\u001b[38;5;241m.\u001b[39mmessage, location\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocation, job_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_id\n\u001b[1;32m   1504\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/google/api_core/retry.py:283\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    280\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    282\u001b[0m )\n\u001b[0;32m--> 283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_deadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/google/api_core/retry.py:190\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, deadline, on_error)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/google/cloud/bigquery/job/query.py:1489\u001b[0m, in \u001b[0;36mQueryJob.result.<locals>.do_get_result\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1486\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_do_query \u001b[38;5;241m=\u001b[39m retry_do_query\n\u001b[1;32m   1487\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_job_retry \u001b[38;5;241m=\u001b[39m job_retry\n\u001b[0;32m-> 1489\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mQueryJob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[38;5;66;03m# Since the job could already be \"done\" (e.g. got a finished job\u001b[39;00m\n\u001b[1;32m   1492\u001b[0m \u001b[38;5;66;03m# via client.get_job), the superclass call to done() might not\u001b[39;00m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;66;03m# set the self._query_results cache.\u001b[39;00m\n\u001b[1;32m   1494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reload_query_results(retry\u001b[38;5;241m=\u001b[39mretry, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/google/cloud/bigquery/job/base.py:728\u001b[0m, in \u001b[0;36m_AsyncJob.result\u001b[0;34m(self, retry, timeout)\u001b[0m\n\u001b[1;32m    725\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_begin(retry\u001b[38;5;241m=\u001b[39mretry, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    727\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {} \u001b[38;5;28;01mif\u001b[39;00m retry \u001b[38;5;129;01mis\u001b[39;00m DEFAULT_RETRY \u001b[38;5;28;01melse\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mretry\u001b[39m\u001b[38;5;124m\"\u001b[39m: retry}\n\u001b[0;32m--> 728\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_AsyncJob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/google/api_core/future/polling.py:137\u001b[0m, in \u001b[0;36mPollingFuture.result\u001b[0;34m(self, timeout, retry)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking_poll(timeout\u001b[38;5;241m=\u001b[39mtimeout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;66;03m# pylint: disable=raising-bad-type\u001b[39;00m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;66;03m# Pylint doesn't recognize that this is valid in this case.\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "\u001b[0;31mBadRequest\u001b[0m: 400 Resources exceeded during query execution: The query could not be executed in the allotted memory. Peak usage: 123% of limit.\nTop memory consumer(s):\n  ORDER BY operations: 99%\n  other/unattributed: 1%\n\n\nLocation: EU\nJob ID: d7a36c40-02a1-441e-a781-e02b192b843a\n"
     ]
    }
   ],
   "source": [
    "job_config = bigquery.QueryJobConfig(\n",
    "    use_legacy_sql=False\n",
    ")\n",
    "\n",
    "df = (\n",
    "    bigquery_client.query(query_string, job_config)\n",
    "    .result()\n",
    "    .to_dataframe(\n",
    "        # Optionally, explicitly request to use the BigQuery Storage API. As of\n",
    "        # google-cloud-bigquery version 1.26.0 and above, the BigQuery Storage\n",
    "        # API is used by default.\n",
    "        create_bqstorage_client=True,\n",
    "    )\n",
    ")\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
